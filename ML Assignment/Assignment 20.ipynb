{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "111120c6",
   "metadata": {},
   "source": [
    "1. What is the underlying concept of Support Vector Machines ?\n",
    "\n",
    "The fundamental idea behind Support Vector Machines is to fit the widest possible “street” between the classes. In other words, the goal is to have the largest possible margin between the decision boundary that separates the two classes and the training instances. When performing soft margin classification, the SVM searches for a compromise between perfectly separating the two classes and having the widest possible street (i.e., a few instances may end up on the street). Another key idea is to use kernels when training on nonlinear datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ae857d4",
   "metadata": {},
   "source": [
    "2. What is the concept of a support vector ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c981ac1e",
   "metadata": {},
   "source": [
    "3. When using SVMs, why is it necessary to scale the inputs ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07ab2a64",
   "metadata": {},
   "source": [
    "4. When an SVM classifier classifies a case, can it output a confidence score? What about a percentage chance ? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0be2162e",
   "metadata": {},
   "source": [
    "5. Should you train a model on a training set with millions of instances and hundreds of features using the primal or dual form of the SVM problem ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a96163dd",
   "metadata": {},
   "source": [
    "6. Let's say you've used an RBF kernel to train an SVM classifier, but it appears to underfit the training collection. Is it better to raise or lower (gamma)? What about the letter C ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b3b649e",
   "metadata": {},
   "source": [
    "7. To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, how should the QP parameters (H, f, A, and b) be set ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54020cf8",
   "metadata": {},
   "source": [
    "8. On a linearly separable dataset, train a LinearSVC. Then, using the same dataset, train an SVC and an SGDClassifier. See if you can get them to make a model that is similar to yours ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9db681d1",
   "metadata": {},
   "source": [
    "9. On the MNIST dataset, train an SVM classifier. You'll need to use one-versus-the-rest to assign all 10 digits because SVM classifiers are binary classifiers. To accelerate up the process, you might want to tune the hyperparameters using small validation sets. What level of precision can you achieve ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b686929",
   "metadata": {},
   "source": [
    "10. On the California housing dataset, train an SVM regressor ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
